# AudioMDB Dataset Conversion Configuration
# Choose converter type: "hf" for HuggingFace datasets, "file" for manifest-based datasets
converter:
  type: "hf"  # Options: "hf", "file"
  
  # HuggingFace Dataset Configuration (used when type: "hf")
  hf:
    dataset_id: "mozilla-foundation/common_voice_11_0"
    dataset_name: "en"  # Optional: dataset subset name
    split: "train"
    streaming: false
    audio_column: "audio"
    text_column: "sentence"
    store_columns: ["age", "gender", "accent"]  # Optional: additional columns to store
  
  # File-based Dataset Configuration (used when type: "file")
  file:
    manifest_path: "data/train_manifest.jsonl"
    audio_column: "audio_filepath"
    text_column: "text"
    store_columns: ["duration", "speaker"]  # Optional: additional columns to store

# Output Configuration
output:
  directory: "./lmdb_output"
  samples_per_shard: 50000
  map_size: 1099511627776  # 1TB in bytes (1 << 40)

# Processing Configuration
processing:
  sample_rate: 16000
  num_workers: 4

# Processors (uncomment and configure as needed)
processors:
  # Audio Processors
  # audio:
  #   - type: "whisper_features"
  #     model_name: "openai/whisper-small"
  #     keep_original: false
  #   
  #   - type: "audiomentations"
  #     keep_original: true
  #     augmentations:
  #       - name: "AddGaussianNoise"
  #         params:
  #           min_amplitude: 0.001
  #           max_amplitude: 0.015
  #           p: 0.5
  #       - name: "TimeStretch"
  #         params:
  #           min_rate: 0.8
  #           max_rate: 1.25
  #           p: 0.5
  #       - name: "PitchShift"
  #         params:
  #           min_semitones: -4
  #           max_semitones: 4
  #           p: 0.5

  # Text Processors  
  # text:
  #   - type: "whisper_tokenizer"
  #     model_name: "openai/whisper-small"
  #     keep_original: false
  #     max_length: 448
  #     padding: "max_length"
  #     truncation: true

# Example configurations for different use cases:

# Example 1: Simple HF dataset conversion without processing
# converter:
#   type: "hf"
#   hf:
#     dataset_id: "librispeech_asr"
#     split: "train.clean.100"
#     audio_column: "audio"
#     text_column: "text"

# Example 2: File-based dataset with Whisper processing
# converter:
#   type: "file"
#   file:
#     manifest_path: "data/my_dataset.jsonl"
#     audio_column: "audio_filepath"  
#     text_column: "transcription"
# processors:
#   audio:
#     - type: "whisper_features"
#       model_name: "openai/whisper-base"
#       keep_original: false
#   text:
#     - type: "whisper_tokenizer"
#       model_name: "openai/whisper-base"
#       keep_original: false

# Example 3: Dataset with augmentations
# processors:
#   audio:
#     - type: "audiomentations"
#       keep_original: true
#       augmentations:
#         - name: "AddGaussianNoise"
#           params: {min_amplitude: 0.001, max_amplitude: 0.01, p: 0.3}
#         - name: "TimeStretch"
#           params: {min_rate: 0.9, max_rate: 1.1, p: 0.3}
